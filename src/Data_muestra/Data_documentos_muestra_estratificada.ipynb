{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052918df-400b-4edb-a2c2-26418bfd9b0d",
   "metadata": {},
   "source": [
    "# Data documentos (obtencion de muestra estratificada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bfc5b2-b897-4c32-9127-ac5ff75bf85c",
   "metadata": {},
   "source": [
    "En este notebook se obtiene caracteristicas unicas documentos electronicos tipo 33 previo a la union con la data de cada contribuyente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07a5f17-856b-4d62-86bb-4e4a3050b44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Se importan packages necesarios\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from pyspark.sql.types import StringType,TimestampType\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d0152e-b6ef-4448-a2a1-f90702d0b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting spark.hadoop.yarn.resourcemanager.principal to hvega.externo\n"
     ]
    }
   ],
   "source": [
    "#inicio de sesion en spark\n",
    "ss_name = 'Lectura de datos Dashboard'\n",
    "wg_conn = \"spark.kerberos.access.hadoopFileSystems\"\n",
    "db_conn = \"abfs://data@datalakesii.dfs.core.windows.net/\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "      .appName(f\"Ejecucion algoritmo {ss_name}\")  \\\n",
    "      .config(wg_conn, db_conn) \\\n",
    "      .config(\"spark.executor.memory\", \"6g\") \\\n",
    "      .config(\"spark.driver.memory\", \"12g\")\\\n",
    "      .config(\"spark.executor.cores\", \"4\") \\\n",
    "      .config(\"spark.executor.instances\", \"5\") \\\n",
    "      .config(\"spark.driver.maxResultSize\", \"12g\") \\\n",
    "      .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\",\"false\")\n",
    "spark.conf.set(\"spark.sql.parquet.int96RebaseModeInRead\", \"CORRECTED\")\n",
    "spark.conf.set(\"spark.sql.parquet.int96RebaseModeInWrite\", \"CORRECTED\")\n",
    "spark.conf.set(\"spark.sql.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\n",
    "spark.conf.set(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"CORRECTED\")\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", \"2000\")\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc65d567-0979-450a-913a-2e4af97cabad",
   "metadata": {},
   "source": [
    "### Documentos electronicos tipo 33 y caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2285458-cc69-44a1-a8c4-364084529c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hive Session ID = 2e0460e2-370c-447c-bcf6-b24f83f33797\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos de la dte emiso, receptor, folio, monto total, hora y fecha de emision respectivas\n",
    "\n",
    "dte=spark.sql(\"select dhdr_folio,dtdc_codigo,dhdr_fch_emis, dhdr_rut_emisor,dhdr_dv_emisor,dhdr_rut_recep,dhdr_dv_recep,dhdr_mnt_total,dhdr_iva,dhdr_tmst_firma from DWBGDATA.HEADER_DTE_CONSOLIDADA_ENC_SAS_ANALITICA where dtdc_codigo=33\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3033786-d9e0-4815-b8ac-887d5447a64d",
   "metadata": {},
   "source": [
    "## Muestreo de ultimos meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "739afa92-4dea-4084-a659-fbb96e913b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 2. Obtener la última fecha de emisión\n",
    "ultima_fecha_emision = dte.agg(F.max(\"dhdr_fch_emis\")).collect()[0][0]\n",
    "\n",
    "meses_antes = F.add_months(F.lit(ultima_fecha_emision), -3)\n",
    "\n",
    "# 4. Filtrar el DataFrame \n",
    "dte = dte.filter(dte[\"dhdr_fch_emis\"] >= meses_antes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d78ed4b-e12a-44b5-9739-00d58820af8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dhdr_folio',\n",
       " 'dtdc_codigo',\n",
       " 'dhdr_fch_emis',\n",
       " 'dhdr_rut_emisor',\n",
       " 'dhdr_dv_emisor',\n",
       " 'dhdr_rut_recep',\n",
       " 'dhdr_dv_recep',\n",
       " 'dhdr_mnt_total',\n",
       " 'dhdr_iva',\n",
       " 'dhdr_tmst_firma']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dte.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a476b-f5f3-44c3-91cd-ecf14a3e68a4",
   "metadata": {},
   "source": [
    "## Agregar variables de promedio y desviacion estandar de montos e iva para emisor y receptor en el periodo estudiado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289fdc8-194b-424e-bee8-24e050ee8ce7",
   "metadata": {},
   "source": [
    "Se agrega el monto total de emision para el emisor respectivo y el monto total recibido para ese receptor, ambos calculos realizados en la ventana de tiempo correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3629e8d-ba20-480b-b8a0-81c3c3758fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar estadísticas para emis_CONT_RUT\n",
    "agg_emisor = dte.groupBy(\"dhdr_rut_emisor\").agg(\n",
    "    F.avg(\"dhdr_mnt_total\").alias(\"avg_dhdr_mnt_total_emisor\"),\n",
    "    F.stddev(\"dhdr_mnt_total\").alias(\"stddev_dhdr_mnt_total_emisor\"),\n",
    "    F.avg(\"dhdr_iva\").alias(\"avg_dhdr_iva_emisor\"),\n",
    "    F.stddev(\"dhdr_iva\").alias(\"stddev_dhdr_iva_emisor\")\n",
    ")\n",
    "\n",
    "# Agregar estadísticas para recep_CONT_RUT\n",
    "agg_receptor = dte.groupBy(\"dhdr_rut_recep\").agg(\n",
    "    F.avg(\"dhdr_mnt_total\").alias(\"avg_dhdr_mnt_total_receptor\"),\n",
    "    F.stddev(\"dhdr_mnt_total\").alias(\"stddev_dhdr_mnt_total_receptor\"),\n",
    "    F.avg(\"dhdr_iva\").alias(\"avg_dhdr_iva_receptor\"),\n",
    "    F.stddev(\"dhdr_iva\").alias(\"stddev_dhdr_iva_receptor\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04abcefb-84d9-4bb2-b970-2642ad023dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir las estadísticas agregadas para emis_CONT_RUT\n",
    "dte= dte.join(agg_emisor, on=\"dhdr_rut_emisor\", how=\"left\")\n",
    "\n",
    "# Unir las estadísticas agregadas para recep_CONT_RUT\n",
    "dte = dte.join(agg_receptor, on=\"dhdr_rut_recep\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86ea4e7-7814-4868-b13f-4f747ffe32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "dte = dte.withColumn(\"anio\", F.year(\"dhdr_tmst_firma\")) \\\n",
    "         .withColumn(\"mes\", F.month(\"dhdr_tmst_firma\")) \\\n",
    "         .withColumn(\"dia\", F.dayofmonth(\"dhdr_tmst_firma\")) \\\n",
    "         .withColumn(\"hora\", F.hour(\"dhdr_tmst_firma\")) \\\n",
    "         .withColumn(\"es_fin_de_semana\", \n",
    "             F.when(F.date_format(\"dhdr_tmst_firma\", \"u\").cast(\"int\").isin([6, 7]), 1).otherwise(0)) \\\n",
    "         .withColumn(\"bloque_horario\", \n",
    "             F.when((F.col(\"hora\") >= 0) & (F.col(\"hora\") < 6), \"Madrugada\")\n",
    "              .when((F.col(\"hora\") >= 6) & (F.col(\"hora\") < 12), \"Mañana\")\n",
    "              .when((F.col(\"hora\") >= 12) & (F.col(\"hora\") < 19), \"Tarde\")\n",
    "              .otherwise(\"Noche\")) \\\n",
    "         .withColumn(\"dia_semana\", F.dayofweek(\"dhdr_tmst_firma\")) \\\n",
    "         .withColumn(\"semana_mes\", \n",
    "             (F.dayofmonth(\"dhdr_tmst_firma\") - 1) / 7 + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d59acbd7-ae0c-4810-96aa-a06f3d3d7def",
   "metadata": {},
   "outputs": [],
   "source": [
    "dte=dte.drop('dhdr_tmst_firma','dhdr_fch_emis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "444e69d2-6d0d-4aa6-9e8d-635485a3052b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dhdr_rut_recep',\n",
       " 'dhdr_rut_emisor',\n",
       " 'dhdr_folio',\n",
       " 'dtdc_codigo',\n",
       " 'dhdr_dv_emisor',\n",
       " 'dhdr_dv_recep',\n",
       " 'dhdr_mnt_total',\n",
       " 'dhdr_iva',\n",
       " 'avg_dhdr_mnt_total_emisor',\n",
       " 'stddev_dhdr_mnt_total_emisor',\n",
       " 'avg_dhdr_iva_emisor',\n",
       " 'stddev_dhdr_iva_emisor',\n",
       " 'avg_dhdr_mnt_total_receptor',\n",
       " 'stddev_dhdr_mnt_total_receptor',\n",
       " 'avg_dhdr_iva_receptor',\n",
       " 'stddev_dhdr_iva_receptor',\n",
       " 'anio',\n",
       " 'mes',\n",
       " 'dia',\n",
       " 'hora',\n",
       " 'es_fin_de_semana',\n",
       " 'bloque_horario',\n",
       " 'dia_semana',\n",
       " 'semana_mes']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dte.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed0e89e-0b9b-4fce-9f65-174cc0fe3117",
   "metadata": {},
   "source": [
    "## Sample estratificado con consideracion de tipo de contribuyente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7f8da47-421f-4493-8cad-6e830ad172a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta donde está el DataFrame de contribuyentes en formato Parquet\n",
    "ruta_contribuyentes = \"abfs://data@datalakesii.dfs.core.windows.net/DatosOrigen/lr-629/APA/Analisis_factura/data_contribuyentes\"\n",
    "\n",
    "# Leer el DataFrame desde la ruta especificada\n",
    "contribuyentes = spark.read.format(\"parquet\").load(ruta_contribuyentes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42056a62-4830-4684-9c36-2db3281c447b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribuyentes.filter(F.col('CONT_RUT').isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a953319-a7c5-447c-a841-956a174f7662",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:================================>                       (20 + 14) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------+\n",
      "|ES_PERSONA|          ES_EMPRESA|   count|\n",
      "+----------+--------------------+--------+\n",
      "|      null|Segmento Pequeñas...|  296711|\n",
      "|      null|                null|  145603|\n",
      "|         1|                null|25381961|\n",
      "|      null|Segmento Micro Em...| 3290283|\n",
      "|      null|Segmento Grandes ...|   76036|\n",
      "|      null|Segmento Medianas...|   50209|\n",
      "+----------+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recuento = contribuyentes.groupBy(\"ES_PERSONA\", \"ES_EMPRESA\").count()\n",
    "# Mostrar el resultado\n",
    "recuento.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abddfa03-2994-4f9f-ac21-8373a18bb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "contribuyentes = contribuyentes.withColumn(\n",
    "    \"tipo_contribuyente\",\n",
    "    F.when(F.col(\"ES_EMPRESA\").isNotNull(), F.col(\"ES_EMPRESA\"))\n",
    "     .when(F.col(\"ES_PERSONA\").isNotNull(), \"Persona\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c5935f0-24c6-4b9c-a5ce-81e7bd799f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:======================================================> (33 + 1) / 34]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|  tipo_contribuyente|   count|\n",
      "+--------------------+--------+\n",
      "|Segmento Pequeñas...|  296711|\n",
      "|                null|  145603|\n",
      "|Segmento Micro Em...| 3290283|\n",
      "|Segmento Grandes ...|   76036|\n",
      "|Segmento Medianas...|   50209|\n",
      "|             Persona|25381961|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "contribuyentes.groupBy(\"tipo_contribuyente\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18197bfa-310c-4c52-a052-c1df811fa050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|  tipo_contribuyente|num_cont_rut_unicos|\n",
      "+--------------------+-------------------+\n",
      "|Segmento Pequeñas...|             174939|\n",
      "|Segmento Micro Em...|             299706|\n",
      "|          indefinido|               1431|\n",
      "|Segmento Grandes ...|              15913|\n",
      "|Segmento Medianas...|              31860|\n",
      "|             Persona|                341|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                0]]]\r"
     ]
    }
   ],
   "source": [
    "# 1. Realizar el left join para incluir la columna 'tipo_contribuyente' en el DataFrame de emisores\n",
    "dte_contribuyentes_emisor = dte.join(\n",
    "    contribuyentes,\n",
    "    (dte[\"dhdr_rut_emisor\"] == contribuyentes[\"CONT_RUT\"]) &\n",
    "    (dte[\"dhdr_dv_emisor\"] == contribuyentes[\"CONT_DV\"]),\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 2. Seleccionar las columnas necesarias y manejar valores nulos en 'tipo_contribuyente'\n",
    "resultado_final_emisor = dte_contribuyentes_emisor.select(\n",
    "    dte[\"*\"],  # Todas las columnas de dte\n",
    "    contribuyentes[\"tipo_contribuyente\"]  # La nueva columna\n",
    ")\n",
    "\n",
    "resultado_final_emisor = resultado_final_emisor.withColumn(\n",
    "    \"tipo_contribuyente\",\n",
    "    F.when(F.col(\"tipo_contribuyente\").isNull(), \"indefinido\")\n",
    "     .otherwise(F.col(\"tipo_contribuyente\"))\n",
    ")\n",
    "\n",
    "# 3. Contar los valores únicos de 'CONT_RUT' por 'tipo_contribuyente'\n",
    "conteo_por_clase_emisor = resultado_final_emisor.groupBy(\"tipo_contribuyente\") \\\n",
    "                                   .agg(F.countDistinct(\"dhdr_rut_emisor\").alias(\"num_cont_rut_unicos\"))\n",
    "\n",
    "# Mostrar el conteo de valores únicos por clase\n",
    "conteo_por_clase_emisor.show()\n",
    "\n",
    "# 4. Determinar el tamaño mínimo para el muestreo equilibrado\n",
    "min_tamano = conteo_por_clase_emisor.agg(F.min(\"num_cont_rut_unicos\")).first()[0]\n",
    "\n",
    "# 5. Calcular la fracción de muestreo para cada clase\n",
    "fracciones_emisor = conteo_por_clase_emisor.select(\n",
    "    \"tipo_contribuyente\",\n",
    "    (F.lit(min_tamano) / F.col(\"num_cont_rut_unicos\")).alias(\"fraccion\")\n",
    ").rdd.collectAsMap()\n",
    "\n",
    "# 6. Realizar el muestreo equilibrado utilizando las fracciones calculadas\n",
    "dataset_final_emisor = resultado_final_emisor.sampleBy(\"tipo_contribuyente\", fracciones_emisor, seed=42)\n",
    "\n",
    "# 7. Contar el tamaño final del dataset muestreado\n",
    "#print(f\"Tamaño del dataset final calibración emisor: {dataset_final_emisor.count()}\")\n",
    "\n",
    "# 8. Eliminar la columna 'tipo_contribuyente' para el dataset final\n",
    "dataset_final_emisor = dataset_final_emisor.drop('tipo_contribuyente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5eb3d34-2029-4476-980f-5203a0cd33ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                200]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|  tipo_contribuyente|num_cont_rut_unicos|\n",
      "+--------------------+-------------------+\n",
      "|Segmento Pequeñas...|             309750|\n",
      "|Segmento Micro Em...|             256233|\n",
      "|          indefinido|              17308|\n",
      "|Segmento Grandes ...|             324865|\n",
      "|Segmento Medianas...|             250545|\n",
      "|             Persona|              72126|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                200]]]\r"
     ]
    }
   ],
   "source": [
    "# 2. Hacer el left join para hacer un sample de receptores\n",
    "dte_contribuyentes_recep = dte.join(\n",
    "    contribuyentes,\n",
    "    (dte[\"dhdr_rut_recep\"] == contribuyentes[\"CONT_RUT\"]) &\n",
    "    (dte[\"dhdr_dv_recep\"] == contribuyentes[\"CONT_DV\"]),\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "resultado_final_recep = dte_contribuyentes_recep.select(\n",
    "    dte[\"*\"],  # Todas las columnas de dte\n",
    "    contribuyentes[\"tipo_contribuyente\"]  # La nueva columna\n",
    ")\n",
    "\n",
    "resultado_final_recep = resultado_final_recep.withColumn(\n",
    "    \"tipo_contribuyente\",\n",
    "    F.when(F.col(\"tipo_contribuyente\").isNull(), \"indefinido\")\n",
    "     .otherwise(F.col(\"tipo_contribuyente\"))\n",
    ")\n",
    "\n",
    "# 1. Contar los valores únicos de CONT_RUT por tipo_contribuyente\n",
    "conteo_por_clase_recep = resultado_final_recep.groupBy(\"tipo_contribuyente\") \\\n",
    "                                   .agg(F.countDistinct(\"dhdr_rut_emisor\").alias(\"num_cont_rut_unicos\"))\n",
    "\n",
    "# Mostrar el resultado\n",
    "conteo_por_clase_recep.show()\n",
    "\n",
    "# 3. Determinar el tamaño mínimo para el muestreo equilibrado\n",
    "min_tamano = conteo_por_clase_recep.agg(F.min(\"num_cont_rut_unicos\")).first()[0]\n",
    "\n",
    "# 4. Calcular la fracción de muestreo para cada clase\n",
    "fracciones_recep = conteo_por_clase_recep.select(\n",
    "    \"tipo_contribuyente\",\n",
    "    (F.lit(min_tamano) / F.col(\"num_cont_rut_unicos\")).alias(\"fraccion\")\n",
    ").rdd.collectAsMap()\n",
    "\n",
    "# 5. Realizar el muestreo equilibrado\n",
    "dataset_final_recep = resultado_final_recep.sampleBy(\"tipo_contribuyente\", fracciones_recep, seed=42)\n",
    "\n",
    "# 6. Contar el tamaño final del dataset muestreado\n",
    "#print(f\"Tamaño del dataset fina calibracion emisor: {dataset_final_recep.count()}\")\n",
    "dataset_final_recep=dataset_final_recep.drop('tipo_contribuyente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "645e9c07-564e-4dd0-8289-8b3455be3396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 200]]\r"
     ]
    }
   ],
   "source": [
    "# Supongamos que ya tienes dataset_final_emisor y dataset_final_recep\n",
    "\n",
    "# 1. Obtener el tamaño de ambos datasets\n",
    "size_emisor = dataset_final_emisor.count()\n",
    "size_recep = dataset_final_recep.count()\n",
    "\n",
    "# 2. Identificar el dataset más grande y el más pequeño\n",
    "if size_emisor > size_recep:\n",
    "    # Resampleamos el dataset_emisor para que tenga el mismo tamaño que el dataset_recep\n",
    "    fraccion_emisor = size_recep / size_emisor\n",
    "    dataset_final_emisor_resampled = dataset_final_emisor.sample(withReplacement=False, fraction=fraccion_emisor, seed=42)\n",
    "    dataset_final_recep_resampled = dataset_final_recep\n",
    "else:\n",
    "    # Resampleamos el dataset_recep para que tenga el mismo tamaño que el dataset_emisor\n",
    "    fraccion_recep = size_emisor / size_recep\n",
    "    dataset_final_recep_resampled = dataset_final_recep.sample(withReplacement=False, fraction=fraccion_recep, seed=42)\n",
    "    dataset_final_emisor_resampled = dataset_final_emisor\n",
    "\n",
    "# 3. Realizamos la unión de los dos datasets (ahora de tamaño similar)\n",
    "dataset_final = dataset_final_emisor_resampled.union(dataset_final_recep_resampled)\n",
    "\n",
    "# Eliminar filas duplicadas\n",
    "dataset_final = dataset_final.dropDuplicates()\n",
    "\n",
    "# 4. Contamos el tamaño final del dataset combinado\n",
    "#print(f\"Tamaño del dataset final combinado: {dataset_final.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c97e2f0d-c602-481f-9c7a-7e5bba3c4bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 314:(158 + 14) / 200][Stage 315:(138 + 14) / 200][Stage 323:(366 + 4) / 383]]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset final combinado: 3450678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Tamaño del dataset final combinado: {dataset_final.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e40ef28-1def-4a78-aa8a-37dd09eb2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/08 00:00:24 441 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /10.244.29.15:44834 is closed\n",
      "[Stage 343:(4590 + -46) / 4544][Stage 350:(166 + -4) / 162][Stage 363:> (0 + 1) / 72]]]\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Se guarda el archivo final en el datalake. \n",
    "dataset_final .write.mode('overwrite').format(\"parquet\").save(\"abfs://data@datalakesii.dfs.core.windows.net/DatosOrigen/lr-629/APA/Analisis_factura/dtes_muestra_estratificada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd2f0ce-1ed3-4e09-a228-f5f8c53dd50c",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3320bf5c-8f91-4425-9dc3-065bd14826b0",
   "metadata": {},
   "source": [
    "## Cesión de documentos tributarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4a919-23da-4fc2-a414-13550f6730e2",
   "metadata": {},
   "source": [
    "## Completar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ff046b4-acc6-4240-a641-a658e7a3c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doct=spark.table(\"hivenom.csn_doctos_final\")\n",
    "ces=spark.table(\"hivenom.csn_cesion_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ad7f2f5-71d7-405a-951c-6e5582459c60",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'dhdr_fch_emis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Realiza el inner join\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dte_cesion \u001b[38;5;241m=\u001b[39m dte\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m      3\u001b[0m     doct,  \u001b[38;5;66;03m# Asumiendo que ya tienes el DataFrame 'ces'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     (dte\u001b[38;5;241m.\u001b[39mdhdr_folio \u001b[38;5;241m==\u001b[39m doct\u001b[38;5;241m.\u001b[39mrdoc_folio) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      5\u001b[0m     (dte\u001b[38;5;241m.\u001b[39mdhdr_rut_emisor \u001b[38;5;241m==\u001b[39m doct\u001b[38;5;241m.\u001b[39mrdoc_rut_emisor_e) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m      6\u001b[0m     (dte\u001b[38;5;241m.\u001b[39mdhdr_dv_emisor \u001b[38;5;241m==\u001b[39m doct\u001b[38;5;241m.\u001b[39mrdoc_dv_emisor),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m      9\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdhdr_folio,\n\u001b[1;32m     10\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdtdc_codigo,\n\u001b[1;32m     11\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdhdr_rut_emisor,\n\u001b[1;32m     12\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdhdr_dv_emisor,\n\u001b[1;32m     13\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdhdr_rut_recep,\n\u001b[1;32m     14\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdhdr_dv_recep,\n\u001b[1;32m     15\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdhdr_mnt_total,\n\u001b[1;32m     16\u001b[0m     dte\u001b[38;5;241m.\u001b[39mdhdr_iva,\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mdte\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdhdr_fch_emis\u001b[49m,  \u001b[38;5;66;03m# Asegúrate de que esta columna exista en dte\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m*\u001b[39mdoct\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;66;03m# Selecciona todas las columnas de 'ces'\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Agrega la columna 'cedido' para indicar si hay cruce\u001b[39;00m\n\u001b[1;32m     22\u001b[0m dte_cesion \u001b[38;5;241m=\u001b[39m dte_cesion\u001b[38;5;241m.\u001b[39mwithColumn(\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcedido\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     F\u001b[38;5;241m.\u001b[39mwhen(doct\u001b[38;5;241m.\u001b[39mrdoc_folio\u001b[38;5;241m.\u001b[39misNotNull(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSí\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'dhdr_fch_emis'"
     ]
    }
   ],
   "source": [
    "# Realiza el inner join\n",
    "dte_cesion = dte.join(\n",
    "    doct,  # Asumiendo que ya tienes el DataFrame 'ces'\n",
    "    (dte.dhdr_folio == doct.rdoc_folio) &\n",
    "    (dte.dhdr_rut_emisor == doct.rdoc_rut_emisor_e) &\n",
    "    (dte.dhdr_dv_emisor == doct.rdoc_dv_emisor),\n",
    "    \"left\"\n",
    ").select(\n",
    "    dte.dhdr_folio,\n",
    "    dte.dtdc_codigo,\n",
    "    dte.dhdr_rut_emisor,\n",
    "    dte.dhdr_dv_emisor,\n",
    "    dte.dhdr_rut_recep,\n",
    "    dte.dhdr_dv_recep,\n",
    "    dte.dhdr_mnt_total,\n",
    "    dte.dhdr_iva,\n",
    "    dte.dhdr_fch_emis,  # Asegúrate de que esta columna exista en dte\n",
    "    *doct.columns # Selecciona todas las columnas de 'ces'\n",
    ")\n",
    "\n",
    "# Agrega la columna 'cedido' para indicar si hay cruce\n",
    "dte_cesion = dte_cesion.withColumn(\n",
    "    \"cedido\",\n",
    "    F.when(doct.rdoc_folio.isNotNull(), \"Sí\").otherwise(\"No\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940cd0ec-fb36-49fe-a66b-8685e159febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dte_cesion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382b453-8128-4710-9fdb-9a859e7ec050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa por las columnas originales de dte y cuenta las veces que ha sido cedido\n",
    "result = dte_cesion.groupBy(\n",
    "    \"dhdr_folio\",\n",
    "    \"dtdc_codigo\",\n",
    "    \"dhdr_fch_emis\",\n",
    "    \"dhdr_rut_emisor\",\n",
    "    \"dhdr_dv_emisor\",\n",
    "    \"dhdr_rut_recep\",\n",
    "    \"dhdr_dv_recep\",\n",
    "    \"dhdr_mnt_total\",\n",
    "    \"dhdr_iva\"\n",
    ").agg(\n",
    "    F.count(F.when(F.col(\"cedido\") == \"Sí\", 1)).alias(\"veces_cedido\")  # Cuenta solo los cedidos\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c504347-78bb-4bef-91f1-5bceb4635c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8c5fc-360c-494c-afba-3683102ace80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza el left join con dte_cesion\n",
    "dte_cesion_det = dte_cesion.join(\n",
    "    ces,  # Asumiendo que ya tienes el DataFrame 'ces'\n",
    "    dte_cesion.rdoc_codigo == ces.rdoc_codigo,  # Asegúrate de que esta columna exista\n",
    "    \"left\"  # Cambiado a left join\n",
    ").select(\n",
    "    dte_cesion.dhdr_folio,\n",
    "    dte_cesion.dhdr_rut_emisor,\n",
    "    dte_cesion.dhdr_rut_recep\n",
    ")\n",
    "\n",
    "# Muestra el resultado (opcional)\n",
    "dte_cesion_det.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980329c9-c59e-44a6-ac2f-d0a5e2def316",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb31454-5585-4a24-b804-2ec33c8b8505",
   "metadata": {},
   "source": [
    "## Obtencion de documentos de RCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70a574-5f0e-4699-a01d-eb8bea7a0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv=spark.table(\"DWBGDATA.DCV_GENERIC_DET_CONSOLIDADO_SAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c3c07-8d34-4705-9aef-bb816c0a079e",
   "metadata": {},
   "source": [
    "## Cruce con registros de RCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6370876-00ef-4deb-a8bc-806e072a19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza el left join\n",
    "union= dte.join(\n",
    "    rcv,\n",
    "    (dte.dhdr_folio == rcv.det_folio_doc_ref) &\n",
    "    (dte.dhdr_rut_emisor ==rcv.dcv_rut_emisor_e) &\n",
    "    (dte.dhdr_rut_recep == rcv.det_rut_doc_e),\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# Agrega una columna para indicar si hubo cruce\n",
    "union = union.withColumn(\n",
    "    \"cruce_rcv\",\n",
    "    F.when(rcv.det_folio_doc_ref.isNotNull(), \"Sí\").otherwise(\"No\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb1073-89ca-49ba-930f-196b48b65174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona todas las columnas originales de dte y las columnas específicas de rcv\n",
    "df_final = union.select(\n",
    "    dte.dhdr_folio,\n",
    "    dte.dtdc_codigo,\n",
    "    dte.dhdr_fch_emis,\n",
    "    dte.dhdr_rut_emisor,\n",
    "    dte.dhdr_dv_emisor,\n",
    "    dte.dhdr_rut_recep,\n",
    "    dte.dhdr_dv_recep,\n",
    "    dte.dhdr_mnt_total,\n",
    "    dte.dhdr_iva,\n",
    "    rcv.det_emisor_nota,\n",
    "    rcv.det_fch_doc,\n",
    "    rcv.det_fec_creacion,\n",
    "    rcv.tipo_transaccion,\n",
    "    F.when(rcv.det_folio_doc_ref.isNotNull(), \"Sí\").otherwise(\"No\").alias(\"cruce_rcv\")\n",
    ")\n",
    "\n",
    "# Muestra el resultado\n",
    "df_final.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ebbe3-6220-4046-b3a7-8c2658a79917",
   "metadata": {},
   "source": [
    "### Cesion de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67fd752b-a1a1-47e7-9942-d7b790260340",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de38415-9631-415b-8213-41b01c8855f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
